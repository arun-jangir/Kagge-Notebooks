{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/arunjangir245/iris-dataset-exploration-to-model-selection?scriptVersionId=143426602\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:130%; text-align:left\">\n\n<h2 align=\"left\"><font color=#3b2b6b>Introduction:</font></h2>\n    Our task will be to assign irises from a data set according to 4 traits to one of three classes. Let's take a look at them ðŸ‘‡","metadata":{}},{"cell_type":"markdown","source":"![](https://data-flair.training/blogs/wp-content/uploads/sites/2/2021/10/iris-flower.webp)","metadata":{}},{"cell_type":"markdown","source":"    \n<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:130%; text-align:left\">\n\n<h2 align=\"left\"><font color=#3b2b6b>Distribution classes:</font></h2>\n    \nPretty pretty, but I also suggest looking at the distribution of classes in our dataset. It is important that the data be separable, not necessarily linearly partitioned. The main requirement is that what you want to classify should be at least somehow separable in the indicative space. It's trite, but the work is designed for beginners. Let's take a look at the distribution ðŸ‘‡\n","metadata":{}},{"cell_type":"markdown","source":"![](https://www.researchgate.net/publication/321930265/figure/fig4/AS:960500506578945@1606012574194/Clustering-of-iris-dataset-using-ICSO-algorithm-3D-View.gif)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:130%; text-align:left\">\n\n<h2 align=\"left\"><font color=#3b2b6b>Data as table:</font></h2>\n\nA basic table is a two-dimensional grid of data, in which the rows represent individual elements of the dataset, and the columns represent quantities related to each of these elements. In general, we will refer to the rows of the matrix as samples, and the number of rows as n_samples and the the columns of the matrix as features, and the number of columns as n_features.\n\n<h2 align=\"left\"><font color=#3b2b6b>Features matrix:</font></h2>\n    \nThis table layout makes clear that the information can be thought of as a two-dimensional numerical array or matrix, called the features matrix with shape [n_samples, n_features]\n\n<h2 align=\"left\"><font color=#3b2b6b>Target array:</font></h2>\n    \nIn addition to the feature matrix X, we also generally work with a label or target array, which by convention we will usually call y. The target array is usually one dimensional, with length n_samples, and is generally contained in a NumPy array or Pandas Series.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"contents_tabel\"></a>\n<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \n<h2 align=\"left\"><font color=#3b2b6b>Table of Contents:</font></h2>\n    \n**Data Preprocessing:**\n\n* Importing Necessary Libraries\n* Loading DataSet\n* Initial Data Analysis\n* Checking if there are any missing values\n\n**Exploratory Data Analysis(EDA):**\n* Boxplot\n* Scatterplot\n* Jointplot\n* Pairplot\n* Andrews_curves\n\n**Correlation**\n\n**Feature Selection**\n\n**Label Encoding**\n\n**Splitting The Data into Training And Testing Dataset**\n\n**Building Machine learning Models**\n* Random Forest Classifier\n* Logistic Regression\n* KNN\n* Naive Bayes\n* Decision Tree","metadata":{}},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Importing Necessary Libraries</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nFirst of all, I will import all the necessary libraries that we will use throughout the project. This generally includes libraries for data manipulation, data visualization, and others based on the specific needs of the project:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\n\n#Metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import make_scorer, accuracy_score ,precision_score,recall_score,f1_score\n\n#Model Select\nfrom sklearn.model_selection import KFold,train_test_split,cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import  LogisticRegression\nfrom sklearn import linear_model\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:00.557819Z","iopub.execute_input":"2023-09-17T07:02:00.559058Z","iopub.status.idle":"2023-09-17T07:02:03.075434Z","shell.execute_reply.started":"2023-09-17T07:02:00.559013Z","shell.execute_reply":"2023-09-17T07:02:03.074294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Loading the Dataset</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nNext, I will load the dataset into a pandas DataFrame which will facilitate easy manipulation and analysis:","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/irisraw/irisraw.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.077405Z","iopub.execute_input":"2023-09-17T07:02:03.078546Z","iopub.status.idle":"2023-09-17T07:02:03.110377Z","shell.execute_reply.started":"2023-09-17T07:02:03.078507Z","shell.execute_reply":"2023-09-17T07:02:03.109497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:130%; text-align:left\">\n\n<h2 align=\"left\"><font color=#3b2b6b>Dataset Description:</font></h2>\n\n**Variable**   | **Description**\n     \n**Sepal length** | Length of the outermost part of the flower.\n    \n**Sepal Width**  | Width of the outermost part of the flower.\n    \n**Petal Length** | Length of the colorful part of the flower.\n    \n**Petal Width**  | Width of the colorful part of the flower.\n    \n**Species** | The specific type or category of the flower.\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Initial Data Analysis</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n\nFirst I will perform a preliminary analysis to understand the structure and types of data columns:","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.111753Z","iopub.execute_input":"2023-09-17T07:02:03.112381Z","iopub.status.idle":"2023-09-17T07:02:03.138507Z","shell.execute_reply.started":"2023-09-17T07:02:03.112345Z","shell.execute_reply":"2023-09-17T07:02:03.137686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n\n**Machine Learning Terminology**\n\nEach row is an observation (also known as : sample, example, instance, record)\n\nEach column is a feature (also known as: Predictor, attribute, Independent Variable, input, regressor, Covariate)","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.141021Z","iopub.execute_input":"2023-09-17T07:02:03.141347Z","iopub.status.idle":"2023-09-17T07:02:03.169237Z","shell.execute_reply.started":"2023-09-17T07:02:03.14132Z","shell.execute_reply":"2023-09-17T07:02:03.167929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.171278Z","iopub.execute_input":"2023-09-17T07:02:03.172172Z","iopub.status.idle":"2023-09-17T07:02:03.180035Z","shell.execute_reply.started":"2023-09-17T07:02:03.172132Z","shell.execute_reply":"2023-09-17T07:02:03.178918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#describing about the dataset\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.181602Z","iopub.execute_input":"2023-09-17T07:02:03.182333Z","iopub.status.idle":"2023-09-17T07:02:03.220678Z","shell.execute_reply.started":"2023-09-17T07:02:03.182304Z","shell.execute_reply":"2023-09-17T07:02:03.219529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#count the value\ndf['species'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.22418Z","iopub.execute_input":"2023-09-17T07:02:03.224536Z","iopub.status.idle":"2023-09-17T07:02:03.232532Z","shell.execute_reply.started":"2023-09-17T07:02:03.224504Z","shell.execute_reply":"2023-09-17T07:02:03.231532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Checking if there are any missing values\n</span></b>","metadata":{}},{"cell_type":"markdown","source":"![](https://mlxb3uasbvvi.i.optimole.com/w:500/h:374/q:mauto/f:avif/https://www.izen.ai/wp-content/uploads/2019/09/1_Yko3Fem6Tzi74OkYm9Imqg.jpeg)","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.234047Z","iopub.execute_input":"2023-09-17T07:02:03.234866Z","iopub.status.idle":"2023-09-17T07:02:03.253518Z","shell.execute_reply.started":"2023-09-17T07:02:03.234829Z","shell.execute_reply":"2023-09-17T07:02:03.25241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Exploratory Data Analysis(EDA)</span></b>","metadata":{"execution":{"iopub.status.busy":"2023-09-15T14:48:08.072868Z","iopub.execute_input":"2023-09-15T14:48:08.073248Z","iopub.status.idle":"2023-09-15T14:48:08.080959Z","shell.execute_reply.started":"2023-09-15T14:48:08.073219Z","shell.execute_reply":"2023-09-15T14:48:08.079266Z"}}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n\n**EDA (Exploratory Data Analysis)** in simple words is like being a detective for data. It's the process of examining and understanding a dataset before you start building models or making decisions based on the data.\n\n**EDA** is like exploring a new place, looking for clues, and making sense of what you find before making any important decisions. It's a crucial step in the data analysis process.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 1. Relationship between species and sepal length</span></b>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.boxplot(x='species',y='sepal length',data=df.sort_values('sepal length',ascending=False))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.25603Z","iopub.execute_input":"2023-09-17T07:02:03.256702Z","iopub.status.idle":"2023-09-17T07:02:03.663921Z","shell.execute_reply.started":"2023-09-17T07:02:03.256647Z","shell.execute_reply":"2023-09-17T07:02:03.662954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 2. Relationship between species and sepal width</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nA scatter plot is a type of data visualization used to display the relationship between two numeric variables. Each data point in the plot represents a single observation in your dataset, and the position of the point is determined by the values of the two variables being compared. Scatter plots are particularly useful for identifying patterns, trends, and potential outliers in the data.","metadata":{}},{"cell_type":"code","source":"df.plot(kind='scatter',x='sepal width',y='sepal length')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:03.668258Z","iopub.execute_input":"2023-09-17T07:02:03.668643Z","iopub.status.idle":"2023-09-17T07:02:04.005088Z","shell.execute_reply.started":"2023-09-17T07:02:03.668613Z","shell.execute_reply":"2023-09-17T07:02:04.004015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 3. Relationship between sepal width and sepal length</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n\nA jointplot is a type of data visualization in Python, commonly used with the Seaborn library, to explore the relationship between two numeric variables. It combines several plots into one, making it easy to see how the variables are distributed and correlated.","metadata":{}},{"cell_type":"code","source":"sns.jointplot(x=\"sepal length\", y=\"sepal width\", data=df, size=5) ","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:04.006645Z","iopub.execute_input":"2023-09-17T07:02:04.006995Z","iopub.status.idle":"2023-09-17T07:02:04.934571Z","shell.execute_reply.started":"2023-09-17T07:02:04.006967Z","shell.execute_reply":"2023-09-17T07:02:04.930364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 4.Pairplot</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nA pairplot is a graphical representation commonly used in data analysis to visualize the relationships between multiple pairs of variables in a dataset. It's a part of the Seaborn library in Python. A pairplot displays scatterplots for each combination of numerical variables and histograms for the individual variables along the diagonal.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df, hue=\"species\", size=3)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:04.935796Z","iopub.execute_input":"2023-09-17T07:02:04.936103Z","iopub.status.idle":"2023-09-17T07:02:12.989571Z","shell.execute_reply.started":"2023-09-17T07:02:04.936076Z","shell.execute_reply":"2023-09-17T07:02:12.988591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 5.Boxplot</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nA boxplot, also known as a box-and-whisker plot, is a graphical representation of the distribution and spread of a dataset. It provides a visual summary of key statistics such as the median, quartiles, and potential outliers.","metadata":{}},{"cell_type":"code","source":"df.boxplot(by=\"species\", figsize=(12, 6))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:12.990928Z","iopub.execute_input":"2023-09-17T07:02:12.991404Z","iopub.status.idle":"2023-09-17T07:02:14.20599Z","shell.execute_reply.started":"2023-09-17T07:02:12.991375Z","shell.execute_reply":"2023-09-17T07:02:14.204943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 6. Andrews_curves</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n\nAndrews Curves is a data visualization technique used to visualize high-dimensional data by mapping each data point into a curve in a 2D space. This technique is particularly useful for exploring and understanding the overall structure and patterns in multivariate datasets.\n\nAndrews Curves are most commonly used in data exploration and dimensionality reduction tasks, where you want to get a quick overview of how variables are related and whether there are any interesting patterns or groupings in the data.","metadata":{}},{"cell_type":"code","source":"import pandas.plotting\nfrom pandas.plotting import andrews_curves\nandrews_curves(df, \"species\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:14.207354Z","iopub.execute_input":"2023-09-17T07:02:14.207787Z","iopub.status.idle":"2023-09-17T07:02:14.893992Z","shell.execute_reply.started":"2023-09-17T07:02:14.207749Z","shell.execute_reply":"2023-09-17T07:02:14.892913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Correlation</span></b>\n\n![](https://www.mathsisfun.com/data/images/correlation-examples.svg)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T16:23:18.348278Z","iopub.execute_input":"2023-09-15T16:23:18.348699Z","iopub.status.idle":"2023-09-15T16:23:19.454401Z","shell.execute_reply.started":"2023-09-15T16:23:18.348665Z","shell.execute_reply":"2023-09-15T16:23:19.453198Z"}}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n\nNow, when we train any algorithm, the number of features and their correlation plays an important role. If there are features and many of the features are highly correlated, then training an algorithm with all the featues will reduce the accuracy. Thus features selection should be done carefully. This dataset has less featues but still we will see the correlation.","metadata":{}},{"cell_type":"code","source":"numeric_df = df.select_dtypes(include=['number'])  # Select numeric columns\ncorrelation_matrix = numeric_df.corr()\n\n# Display the correlation matrix\nprint(correlation_matrix)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:14.895389Z","iopub.execute_input":"2023-09-17T07:02:14.895716Z","iopub.status.idle":"2023-09-17T07:02:14.905695Z","shell.execute_reply.started":"2023-09-17T07:02:14.895689Z","shell.execute_reply":"2023-09-17T07:02:14.904571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize = (8,8))\nsns.heatmap(correlation_matrix, annot=True,fmt=\"f\").set_title(\"Corelation of attributes (petal length,width and sepal length,width) among Iris species\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:14.907225Z","iopub.execute_input":"2023-09-17T07:02:14.90772Z","iopub.status.idle":"2023-09-17T07:02:15.362199Z","shell.execute_reply.started":"2023-09-17T07:02:14.907681Z","shell.execute_reply":"2023-09-17T07:02:15.360945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \n**Observation**\n\nThe Sepal Width and Length are not correlated The Petal Width and Length are highly correlated\n\nWe will use all the features for training the algorithm and check the accuracy.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Feature Selection</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \n**Dividing data into features and labels**\n    \nAs we can see dataset contain 5 columns: sepal length, sepal width, petal length, petal width and species. The actual features are described by columns 1-4. Last column contains labels of samples. Firstly we need to split data into two arrays: X (features) and y (labels).","metadata":{}},{"cell_type":"markdown","source":"![](https://vitalflux.com/wp-content/uploads/2020/08/Screenshot-2020-08-02-at-5.58.44-PM.png)","metadata":{}},{"cell_type":"code","source":"X=df.iloc[:,0:4].values\ny=df.iloc[:,4].values","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.363818Z","iopub.execute_input":"2023-09-17T07:02:15.364302Z","iopub.status.idle":"2023-09-17T07:02:15.371769Z","shell.execute_reply.started":"2023-09-17T07:02:15.36426Z","shell.execute_reply":"2023-09-17T07:02:15.370534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Label encoding</span></b>","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/772/1*QQe-4476Oy3_dI1vhb3dDg.png)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nAs we can see labels are categorical. KNeighborsClassifier does not accept string labels. We need to use LabelEncoder to transform them into numbers. Iris-setosa correspond to 0, Iris-versicolor correspond to 1 and Iris-virginica correspond to 2.","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\ny = le.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.373986Z","iopub.execute_input":"2023-09-17T07:02:15.374391Z","iopub.status.idle":"2023-09-17T07:02:15.385241Z","shell.execute_reply.started":"2023-09-17T07:02:15.374358Z","shell.execute_reply":"2023-09-17T07:02:15.384017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Splitting The Data into Training And Testing Dataset</span></b>","metadata":{}},{"cell_type":"code","source":"#Train and Test split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.386695Z","iopub.execute_input":"2023-09-17T07:02:15.387727Z","iopub.status.idle":"2023-09-17T07:02:15.400136Z","shell.execute_reply.started":"2023-09-17T07:02:15.387678Z","shell.execute_reply":"2023-09-17T07:02:15.399209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nNow we will train several Machine Learning models and compare their results. Note that because the dataset does not provide labels for their testing-set, we need to use the predictions on the training set to compare the algorithms with each other.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Building Machine Learning Models</span></b>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 1.Random Forest</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nRandom forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our modelâ€™s prediction.\n\nA large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.","metadata":{}},{"cell_type":"markdown","source":"![](https://av-eks-blogoptimized.s3.amazonaws.com/33019random-forest-algorithm287548.png)","metadata":{}},{"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_prediction = random_forest.predict(X_test)\naccuracy_rf=round(accuracy_score(y_test,Y_prediction)* 100, 2)\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n\n\ncm = confusion_matrix(y_test, Y_prediction)\naccuracy = accuracy_score(y_test,Y_prediction)\nprecision =precision_score(y_test, Y_prediction,average='micro')\nrecall =  recall_score(y_test, Y_prediction,average='micro')\nf1 = f1_score(y_test,Y_prediction,average='micro')\nprint('Confusion matrix for Random Forest\\n',cm)\nprint('accuracy_random_Forest : %.3f' %accuracy)\nprint('precision_random_Forest : %.3f' %precision)\nprint('recall_random_Forest : %.3f' %recall)\nprint('f1-score_random_Forest : %.3f' %f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.401266Z","iopub.execute_input":"2023-09-17T07:02:15.402904Z","iopub.status.idle":"2023-09-17T07:02:15.662589Z","shell.execute_reply.started":"2023-09-17T07:02:15.402841Z","shell.execute_reply":"2023-09-17T07:02:15.661254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 2.Logistic Regression</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nLogistic Regression is a Machine Learning algorithm which is used for the classification problems, it is a predictive analysis algorithm and based on the concept of probability.\n\nWe can call a Logistic Regression a Linear Regression model but the Logistic Regression uses a more complex cost function, this cost function can be defined as the â€˜Sigmoid functionâ€™ or also known as the â€˜logistic functionâ€™ instead of a linear function.","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/v2/resize:fit:966/1*KoAzQLM1zDi5s9yTR9V6hw.png)","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression(solver= 'lbfgs',max_iter=400)\nlogreg.fit(X_train, y_train)\nY_pred = logreg.predict(X_test)\naccuracy_lr=round(accuracy_score(y_test,Y_pred)* 100, 2)\nacc_log = round(logreg.score(X_train, y_train) * 100, 2)\n\n\ncm = confusion_matrix(y_test, Y_pred,)\naccuracy = accuracy_score(y_test,Y_pred)\nprecision =precision_score(y_test, Y_pred,average='micro')\nrecall =  recall_score(y_test, Y_pred,average='micro')\nf1 = f1_score(y_test,Y_pred,average='micro')\nprint('Confusion matrix for Logistic Regression\\n',cm)\nprint('accuracy_Logistic Regression : %.3f' %accuracy)\nprint('precision_Logistic Regression : %.3f' %precision)\nprint('recall_Logistic Regression: %.3f' %recall)\nprint('f1-score_Logistic Regression : %.3f' %f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.664117Z","iopub.execute_input":"2023-09-17T07:02:15.665051Z","iopub.status.idle":"2023-09-17T07:02:15.70842Z","shell.execute_reply.started":"2023-09-17T07:02:15.665017Z","shell.execute_reply":"2023-09-17T07:02:15.707326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 3. K Nearest Neighbor</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nK-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique.\n\nK-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories.\n\nK-NN algorithm stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.","metadata":{}},{"cell_type":"markdown","source":"![](https://cambridgecoding.files.wordpress.com/2016/01/knn2.jpg)","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\nY_pred = knn.predict(X_test) \naccuracy_knn=round(accuracy_score(y_test,Y_pred)* 100, 2)\nacc_knn = round(knn.score(X_train, y_train) * 100, 2)\n\ncm = confusion_matrix(y_test, Y_pred)\naccuracy = accuracy_score(y_test,Y_pred)\nprecision =precision_score(y_test, Y_pred,average='micro')\nrecall =  recall_score(y_test, Y_pred,average='micro')\nf1 = f1_score(y_test,Y_pred,average='micro')\nprint('Confusion matrix for KNN\\n',cm)\nprint('accuracy_KNN : %.3f' %accuracy)\nprint('precision_KNN : %.3f' %precision)\nprint('recall_KNN: %.3f' %recall)\nprint('f1-score_KNN : %.3f' %f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.70976Z","iopub.execute_input":"2023-09-17T07:02:15.710218Z","iopub.status.idle":"2023-09-17T07:02:15.74335Z","shell.execute_reply.started":"2023-09-17T07:02:15.710183Z","shell.execute_reply":"2023-09-17T07:02:15.742419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 4. Gaussian Naive Bayes</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nNaive Bayes is a classification algorithm for binary (two-class) and multi-class classification problems. The technique is easiest to understand when described using binary or categorical input values.\n\nIt is called naive Bayes or idiot Bayes because the calculation of the probabilities for each hypothesis are simplified to make their calculation tractable. Rather than attempting to calculate the values of each attribute value P(d1, d2, d3|h), they are assumed to be conditionally independent given the target value and calculated as P(d1|h) * P(d2|H) and so on.\n\nThis is a very strong assumption that is most unlikely in real data, i.e. that the attributes do not interact. Nevertheless, the approach performs surprisingly well on data where this assumption does not hold.","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/v2/resize:fit:1200/0*qFuHAV7Vd09064q-.jpeg)","metadata":{}},{"cell_type":"code","source":"gaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\nY_pred = gaussian.predict(X_test) \naccuracy_nb=round(accuracy_score(y_test,Y_pred)* 100, 2)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n\ncm = confusion_matrix(y_test, Y_pred)\naccuracy = accuracy_score(y_test,Y_pred)\nprecision =precision_score(y_test, Y_pred,average='micro')\nrecall =  recall_score(y_test, Y_pred,average='micro')\nf1 = f1_score(y_test,Y_pred,average='micro')\nprint('Confusion matrix for Naive Bayes\\n',cm)\nprint('accuracy_Naive Bayes: %.3f' %accuracy)\nprint('precision_Naive Bayes: %.3f' %precision)\nprint('recall_Naive Bayes: %.3f' %recall)\nprint('f1-score_Naive Bayes : %.3f' %f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.744475Z","iopub.execute_input":"2023-09-17T07:02:15.744847Z","iopub.status.idle":"2023-09-17T07:02:15.763288Z","shell.execute_reply.started":"2023-09-17T07:02:15.744819Z","shell.execute_reply":"2023-09-17T07:02:15.762404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> 5. Decision Tree</span></b>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nA decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails) , each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class labels. The paths from root to leaf represent classification rules.","metadata":{}},{"cell_type":"markdown","source":"![](https://regenerativetoday.com/wp-content/uploads/2022/04/dt.png)","metadata":{}},{"cell_type":"code","source":"decision_tree = DecisionTreeClassifier() \ndecision_tree.fit(X_train, y_train)  \nY_pred = decision_tree.predict(X_test) \naccuracy_dt=round(accuracy_score(y_test,Y_pred)* 100, 2)\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\n\ncm = confusion_matrix(y_test, Y_pred)\naccuracy = accuracy_score(y_test,Y_pred)\nprecision =precision_score(y_test, Y_pred,average='micro')\nrecall =  recall_score(y_test, Y_pred,average='micro')\nf1 = f1_score(y_test,Y_pred,average='micro')\nprint('Confusion matrix for DecisionTree\\n',cm)\nprint('accuracy_DecisionTree: %.3f' %accuracy)\nprint('precision_DecisionTree: %.3f' %precision)\nprint('recall_DecisionTree: %.3f' %recall)\nprint('f1-score_DecisionTree : %.3f' %f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.764235Z","iopub.execute_input":"2023-09-17T07:02:15.764544Z","iopub.status.idle":"2023-09-17T07:02:15.783231Z","shell.execute_reply.started":"2023-09-17T07:02:15.764518Z","shell.execute_reply":"2023-09-17T07:02:15.782221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import plot_tree\nplt.figure(figsize = (15,10))\nplot_tree(decision_tree.fit(X_train, y_train)  ,filled=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:15.784533Z","iopub.execute_input":"2023-09-17T07:02:15.784915Z","iopub.status.idle":"2023-09-17T07:02:16.475507Z","shell.execute_reply.started":"2023-09-17T07:02:15.784888Z","shell.execute_reply":"2023-09-17T07:02:16.474665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"libraries\"></a>\n# <b><span style='color:#9900cc'> Which is the best Model ?</span></b>","metadata":{}},{"cell_type":"code","source":"results = pd.DataFrame({\n    'Model': [ 'KNN', \n              'Logistic Regression', \n              'Random Forest',\n              'Naive Bayes',  \n              'Decision Tree'],\n    'Score': [ acc_knn,\n              acc_log, \n              acc_random_forest,\n              acc_gaussian,\n              acc_decision_tree],\n    \"Accuracy_score\":[accuracy_knn,\n                      accuracy_lr,\n                      accuracy_rf,\n                      accuracy_nb,\n                      accuracy_dt\n                     ]})\nresult_df = results.sort_values(by='Accuracy_score', ascending=False)\nresult_df = result_df.reset_index(drop=True)\nresult_df.head(9)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:02:16.476549Z","iopub.execute_input":"2023-09-17T07:02:16.477061Z","iopub.status.idle":"2023-09-17T07:02:16.491178Z","shell.execute_reply.started":"2023-09-17T07:02:16.477034Z","shell.execute_reply":"2023-09-17T07:02:16.490244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \nAs we see best Model is given by Naive Bayes(100% Accuracy).","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #9d8cd1; font-size:120%; text-align:left\">\n    \n**Observations:**\n    \nThis was expected as we saw in the heatmap above that the correlation between the Sepal Width and Length was very low whereas the correlation between Petal Width and Length was very high. Thus we have just implemented some of the common Machine Learning. Since the dataset is small with very few features.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; padding: 15px; background-color: #b3ffcc; font-size:120%; text-align:left\">\n    \nIf you've made it this far, I hope you found my analysis enjoyable and informative.\n\nIf you found it helpful, please consider upvoting!\n\nAs a beginner, I welcome any suggestions and feedback in the comments section. Your input is highly valuable.\n\nIf you have any questions or uncertainties about any part of the notebook, please don't hesitate to leave a comment with your inquiries.\n\n**Thank you for your time and attention!**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}